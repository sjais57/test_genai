from onnxruntime.quantization import quantize_dynamic, QuantType

quantize_dynamic(
    model_input="distilbert.onnx",
    model_output="distilbert-quant.onnx",
    weight_type=QuantType.QInt8
)


import onnxruntime as ort

def run_inference(model_path, input_text):
    ort_session = ort.InferenceSession(model_path)
    inputs = tokenizer(input_text, return_tensors="np", padding=True)
    ort_inputs = {k: v for k, v in inputs.items()}
    outputs = ort_session.run(None, ort_inputs)
    return outputs

# Compare outputs
text = "I love this movie!"
original_out = run_inference("distilbert.onnx", text)
quantized_out = run_inference("distilbert-quant.onnx", text)

print("Original:", original_out)
print("Quantized:", quantized_out)


üß™ Optional: Add Cosine Similarity
from scipy.spatial.distance import cosine

score = 1 - cosine(original_out[0][0], quantized_out[0][0])
print("Cosine Similarity:", score)


üß† Example: Inspect Weights of a Hugging Face Model

from transformers import AutoModel

model = AutoModel.from_pretrained("bert-base-uncased")

# Accessing weight tensors of a specific layer
for name, param in model.named_parameters():
    if param.requires_grad:
        print(f"{name} - dtype: {param.dtype} - shape: {param.shape}")
        print(param.data[:2])  # print sample weights

output: encoder.layer.0.attention.self.query.weight - dtype: torch.float32


üîç 2. Checking Activations (Intermediate Outputs)
import torch

activations = {}

def get_activation(name):
    def hook(model, input, output):
        activations[name] = output.detach()
    return hook

# Example: hook into BERT‚Äôs first encoder layer
layer = model.encoder.layer[0].output
layer.register_forward_hook(get_activation("layer0_output"))


üß™ Run a Forward Pass
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
inputs = tokenizer("hello world", return_tensors="pt")

with torch.no_grad():
    _ = model(**inputs)

# Check activations
print("Activation dtype:", activations["layer0_output"].dtype)
print("Activation sample:", activations["layer0_output"][0, :2, :4])  # batch x tokens x features


torch.save(activations["layer0_output"], "fp32_activations.pt")
torch.save(model.state_dict(), "fp32_weights.pt")

